{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Process for age estimation stochastic process\n",
    "\n",
    "This notebook shows how to train and sample from a Neural Process for age estimation\n",
    "\n",
    "We select the FG-net, each person as a batch. In each batch, there are 18 persons.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import FaceFeatureData\n",
    "\n",
    "# Create dataset\n",
    "\n",
    "dataset = FaceFeatureData(num_of_people=3,num_of_images=18)\n",
    "\n",
    "#82 different people(batch_num)\n",
    "#18 different images each people(batch_size)\n",
    "#x_dim = 2048\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Neural Process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from neural_process import NeuralProcess\n",
    "\n",
    "x_dim = 2048\n",
    "y_dim = 1\n",
    "r_dim = 50  # Dimension of representation of context points\n",
    "z_dim = 50  # Dimension of sampled latent variable\n",
    "h_dim = 50  # Dimension of hidden layers in encoder and decoder\n",
    "\n",
    "neuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Neural Process\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch: 0, Avg_loss: 15460.656412760416\n",
      "Epoch: 1, Avg_loss: 14594.693522135416\n",
      "Epoch: 2, Avg_loss: 13731.248860677084\n",
      "Epoch: 3, Avg_loss: 12721.38232421875\n",
      "Epoch: 4, Avg_loss: 11822.476236979166\n",
      "Epoch: 5, Avg_loss: 10954.656575520834\n",
      "Epoch: 6, Avg_loss: 9743.961263020834\n",
      "Epoch: 7, Avg_loss: 8528.200358072916\n",
      "Epoch: 8, Avg_loss: 7703.194580078125\n",
      "Epoch: 9, Avg_loss: 6374.939697265625\n",
      "Epoch: 10, Avg_loss: 5467.244954427083\n",
      "Epoch: 11, Avg_loss: 4883.371826171875\n",
      "Epoch: 12, Avg_loss: 3996.8824869791665\n",
      "Epoch: 13, Avg_loss: 3155.6392822265625\n",
      "Epoch: 14, Avg_loss: 2644.724650065104\n",
      "Epoch: 15, Avg_loss: 2220.04296875\n",
      "Epoch: 16, Avg_loss: 1814.9436848958333\n",
      "Epoch: 17, Avg_loss: 1569.371602376302\n",
      "Epoch: 18, Avg_loss: 1328.9509684244792\n",
      "Epoch: 19, Avg_loss: 1040.9008687337239\n",
      "Epoch: 20, Avg_loss: 875.2627461751302\n",
      "Epoch: 21, Avg_loss: 731.4236653645834\n",
      "Epoch: 22, Avg_loss: 610.3392435709635\n",
      "Epoch: 23, Avg_loss: 519.0230560302734\n",
      "Epoch: 24, Avg_loss: 439.87135823567706\n",
      "Epoch: 25, Avg_loss: 345.91916910807294\n",
      "Epoch: 26, Avg_loss: 283.7828318277995\n",
      "Epoch: 27, Avg_loss: 252.47874959309897\n",
      "Epoch: 28, Avg_loss: 219.5202433268229\n",
      "Epoch: 29, Avg_loss: 186.88418324788412\n",
      "Epoch: 30, Avg_loss: 174.15001932779947\n",
      "Epoch: 31, Avg_loss: 155.55014038085938\n",
      "Epoch: 32, Avg_loss: 144.73729451497397\n",
      "Epoch: 33, Avg_loss: 133.4148203531901\n",
      "Epoch: 34, Avg_loss: 132.12875111897787\n",
      "Epoch: 35, Avg_loss: 122.24464162190755\n",
      "Epoch: 36, Avg_loss: 122.40029398600261\n",
      "Epoch: 37, Avg_loss: 114.40469868977864\n",
      "Epoch: 38, Avg_loss: 106.13268280029297\n",
      "Epoch: 39, Avg_loss: 104.83590443929036\n",
      "Epoch: 40, Avg_loss: 102.3916244506836\n",
      "Epoch: 41, Avg_loss: 101.56534830729167\n",
      "Epoch: 42, Avg_loss: 97.95641581217448\n",
      "Epoch: 43, Avg_loss: 99.69339497884114\n",
      "Epoch: 44, Avg_loss: 97.4177754720052\n",
      "Epoch: 45, Avg_loss: 93.14895121256511\n",
      "Epoch: 46, Avg_loss: 97.433349609375\n",
      "Epoch: 47, Avg_loss: 92.64505767822266\n",
      "Epoch: 48, Avg_loss: 93.27860005696614\n",
      "Epoch: 49, Avg_loss: 93.65981038411458\n",
      "Epoch: 50, Avg_loss: 90.28374735514323\n",
      "Epoch: 51, Avg_loss: 90.82039133707683\n",
      "Epoch: 52, Avg_loss: 92.01598612467448\n",
      "Epoch: 53, Avg_loss: 88.32655334472656\n",
      "Epoch: 54, Avg_loss: 88.53752899169922\n",
      "Epoch: 55, Avg_loss: 93.3680191040039\n",
      "Epoch: 56, Avg_loss: 87.24212900797527\n",
      "Epoch: 57, Avg_loss: 90.46026102701823\n",
      "Epoch: 58, Avg_loss: 85.92184448242188\n",
      "Epoch: 59, Avg_loss: 91.65413157145183\n",
      "Epoch: 60, Avg_loss: 88.06900024414062\n",
      "Epoch: 61, Avg_loss: 84.95762634277344\n",
      "Epoch: 62, Avg_loss: 86.70391082763672\n",
      "Epoch: 63, Avg_loss: 86.63111114501953\n",
      "Epoch: 64, Avg_loss: 88.51432037353516\n",
      "Epoch: 65, Avg_loss: 86.82470448811848\n",
      "iteration 200, loss 75.346\n",
      "Epoch: 66, Avg_loss: 83.83116404215495\n",
      "Epoch: 67, Avg_loss: 84.5657450358073\n",
      "Epoch: 68, Avg_loss: 88.18625132242839\n",
      "Epoch: 69, Avg_loss: 85.9471944173177\n",
      "Epoch: 70, Avg_loss: 85.06576538085938\n",
      "Epoch: 71, Avg_loss: 86.22152964274089\n",
      "Epoch: 72, Avg_loss: 84.03687032063802\n",
      "Epoch: 73, Avg_loss: 85.60791778564453\n",
      "Epoch: 74, Avg_loss: 84.30817159016927\n",
      "Epoch: 75, Avg_loss: 85.65574645996094\n",
      "Epoch: 76, Avg_loss: 85.06984202067058\n",
      "Epoch: 77, Avg_loss: 82.75105794270833\n",
      "Epoch: 78, Avg_loss: 84.23334503173828\n",
      "Epoch: 79, Avg_loss: 82.48497517903645\n",
      "Epoch: 80, Avg_loss: 84.75709788004558\n",
      "Epoch: 81, Avg_loss: 83.62828063964844\n",
      "Epoch: 82, Avg_loss: 84.46369934082031\n",
      "Epoch: 83, Avg_loss: 82.92165120442708\n",
      "Epoch: 84, Avg_loss: 82.68972778320312\n",
      "Epoch: 85, Avg_loss: 81.6454849243164\n",
      "Epoch: 86, Avg_loss: 81.73868815104167\n",
      "Epoch: 87, Avg_loss: 82.59840138753255\n",
      "Epoch: 88, Avg_loss: 84.85902913411458\n",
      "Epoch: 89, Avg_loss: 81.92967224121094\n",
      "Epoch: 90, Avg_loss: 82.18985493977864\n",
      "Epoch: 91, Avg_loss: 83.02682495117188\n",
      "Epoch: 92, Avg_loss: 81.66112772623698\n",
      "Epoch: 93, Avg_loss: 81.35143788655598\n",
      "Epoch: 94, Avg_loss: 81.48746999104817\n",
      "Epoch: 95, Avg_loss: 81.68189748128255\n",
      "Epoch: 96, Avg_loss: 81.98510487874348\n",
      "Epoch: 97, Avg_loss: 80.96875254313152\n",
      "Epoch: 98, Avg_loss: 84.54282124837239\n",
      "Epoch: 99, Avg_loss: 83.1212895711263\n",
      "Epoch: 100, Avg_loss: 82.51343790690105\n",
      "Epoch: 101, Avg_loss: 81.70266723632812\n",
      "Epoch: 102, Avg_loss: 82.8130391438802\n",
      "Epoch: 103, Avg_loss: 82.39755249023438\n",
      "Epoch: 104, Avg_loss: 80.5718765258789\n",
      "Epoch: 105, Avg_loss: 80.86218516031902\n",
      "Epoch: 106, Avg_loss: 81.13431294759114\n",
      "Epoch: 107, Avg_loss: 80.84989929199219\n",
      "Epoch: 108, Avg_loss: 80.17056528727214\n",
      "Epoch: 109, Avg_loss: 80.83351389567058\n",
      "Epoch: 110, Avg_loss: 80.92288462320964\n",
      "Epoch: 111, Avg_loss: 80.64779663085938\n",
      "Epoch: 112, Avg_loss: 80.93201446533203\n",
      "Epoch: 113, Avg_loss: 80.63031514485677\n",
      "Epoch: 114, Avg_loss: 81.04258982340495\n",
      "Epoch: 115, Avg_loss: 80.98535410563152\n",
      "Epoch: 116, Avg_loss: 79.81933339436848\n",
      "Epoch: 117, Avg_loss: 80.81358591715495\n",
      "Epoch: 118, Avg_loss: 79.86938985188802\n",
      "Epoch: 119, Avg_loss: 80.34878031412761\n",
      "Epoch: 120, Avg_loss: 80.73058064778645\n",
      "Epoch: 121, Avg_loss: 79.8489507039388\n",
      "Epoch: 122, Avg_loss: 80.26528930664062\n",
      "Epoch: 123, Avg_loss: 79.65231577555339\n",
      "Epoch: 124, Avg_loss: 80.00126647949219\n",
      "Epoch: 125, Avg_loss: 80.04681905110677\n",
      "Epoch: 126, Avg_loss: 79.57416280110677\n",
      "Epoch: 127, Avg_loss: 79.98985290527344\n",
      "Epoch: 128, Avg_loss: 79.98727162679036\n",
      "Epoch: 129, Avg_loss: 80.35211181640625\n",
      "Epoch: 130, Avg_loss: 79.63159688313802\n",
      "Epoch: 131, Avg_loss: 80.60443369547527\n",
      "Epoch: 132, Avg_loss: 80.06856282552083\n",
      "iteration 400, loss 88.142\n",
      "Epoch: 133, Avg_loss: 80.4577128092448\n",
      "Epoch: 134, Avg_loss: 79.60282897949219\n",
      "Epoch: 135, Avg_loss: 80.02195739746094\n",
      "Epoch: 136, Avg_loss: 80.40735371907552\n",
      "Epoch: 137, Avg_loss: 80.21727498372395\n",
      "Epoch: 138, Avg_loss: 79.96074676513672\n",
      "Epoch: 139, Avg_loss: 79.8730951944987\n",
      "Epoch: 140, Avg_loss: 80.21776072184245\n",
      "Epoch: 141, Avg_loss: 79.67438252766927\n",
      "Epoch: 142, Avg_loss: 79.91075134277344\n",
      "Epoch: 143, Avg_loss: 79.8863042195638\n",
      "Epoch: 144, Avg_loss: 79.35868835449219\n",
      "Epoch: 145, Avg_loss: 79.43255869547527\n",
      "Epoch: 146, Avg_loss: 79.36269632975261\n",
      "Epoch: 147, Avg_loss: 79.61200714111328\n",
      "Epoch: 148, Avg_loss: 79.0748774210612\n",
      "Epoch: 149, Avg_loss: 79.65865325927734\n",
      "Epoch: 150, Avg_loss: 78.90797932942708\n",
      "Epoch: 151, Avg_loss: 79.50505828857422\n",
      "Epoch: 152, Avg_loss: 79.63000996907552\n",
      "Epoch: 153, Avg_loss: 79.70275115966797\n",
      "Epoch: 154, Avg_loss: 79.59376271565755\n",
      "Epoch: 155, Avg_loss: 79.62488047281902\n",
      "Epoch: 156, Avg_loss: 79.2882792154948\n",
      "Epoch: 157, Avg_loss: 79.06167093912761\n",
      "Epoch: 158, Avg_loss: 79.32084655761719\n",
      "Epoch: 159, Avg_loss: 78.95394134521484\n",
      "Epoch: 160, Avg_loss: 78.95620727539062\n",
      "Epoch: 161, Avg_loss: 79.38087463378906\n",
      "Epoch: 162, Avg_loss: 79.43619028727214\n",
      "Epoch: 163, Avg_loss: 78.95552825927734\n",
      "Epoch: 164, Avg_loss: 78.77620442708333\n",
      "Epoch: 165, Avg_loss: 78.83200073242188\n",
      "Epoch: 166, Avg_loss: 78.76035817464192\n",
      "Epoch: 167, Avg_loss: 79.5624771118164\n",
      "Epoch: 168, Avg_loss: 79.23341623942058\n",
      "Epoch: 169, Avg_loss: 79.28467814127605\n",
      "Epoch: 170, Avg_loss: 78.57658131917317\n",
      "Epoch: 171, Avg_loss: 78.8882319132487\n",
      "Epoch: 172, Avg_loss: 78.52352905273438\n",
      "Epoch: 173, Avg_loss: 78.55565134684245\n",
      "Epoch: 174, Avg_loss: 78.37648264567058\n",
      "Epoch: 175, Avg_loss: 78.52039591471355\n",
      "Epoch: 176, Avg_loss: 78.84828694661458\n",
      "Epoch: 177, Avg_loss: 78.03753662109375\n",
      "Epoch: 178, Avg_loss: 78.25212097167969\n",
      "Epoch: 179, Avg_loss: 78.10823822021484\n",
      "Epoch: 180, Avg_loss: 78.1209487915039\n",
      "Epoch: 181, Avg_loss: 78.02648417154948\n",
      "Epoch: 182, Avg_loss: 78.98162333170573\n",
      "Epoch: 183, Avg_loss: 78.62810770670573\n",
      "Epoch: 184, Avg_loss: 78.39969126383464\n",
      "Epoch: 185, Avg_loss: 78.32576751708984\n",
      "Epoch: 186, Avg_loss: 78.14428456624348\n",
      "Epoch: 187, Avg_loss: 78.15391031901042\n",
      "Epoch: 188, Avg_loss: 77.9774881998698\n",
      "Epoch: 189, Avg_loss: 78.02674357096355\n",
      "Epoch: 190, Avg_loss: 77.74425760904948\n",
      "Epoch: 191, Avg_loss: 77.89349873860677\n",
      "Epoch: 192, Avg_loss: 77.82249196370442\n",
      "Epoch: 193, Avg_loss: 77.41046396891277\n",
      "Epoch: 194, Avg_loss: 77.89757537841797\n",
      "Epoch: 195, Avg_loss: 78.00410715738933\n",
      "Epoch: 196, Avg_loss: 77.70363108317058\n",
      "Epoch: 197, Avg_loss: 77.43345387776692\n",
      "Epoch: 198, Avg_loss: 77.22478485107422\n",
      "iteration 600, loss 83.772\n",
      "Epoch: 199, Avg_loss: 77.29067484537761\n",
      "Epoch: 200, Avg_loss: 77.27448018391927\n",
      "Epoch: 201, Avg_loss: 77.31007893880208\n",
      "Epoch: 202, Avg_loss: 76.87644449869792\n",
      "Epoch: 203, Avg_loss: 76.93937683105469\n",
      "Epoch: 204, Avg_loss: 77.06307983398438\n",
      "Epoch: 205, Avg_loss: 76.95404052734375\n",
      "Epoch: 206, Avg_loss: 76.59047953287761\n",
      "Epoch: 207, Avg_loss: 76.99468485514323\n",
      "Epoch: 208, Avg_loss: 76.43475341796875\n",
      "Epoch: 209, Avg_loss: 76.82736206054688\n",
      "Epoch: 210, Avg_loss: 76.29392751057942\n",
      "Epoch: 211, Avg_loss: 76.27841695149739\n",
      "Epoch: 212, Avg_loss: 76.97777048746745\n",
      "Epoch: 213, Avg_loss: 76.3241704305013\n",
      "Epoch: 214, Avg_loss: 76.47641499837239\n",
      "Epoch: 215, Avg_loss: 76.23658752441406\n",
      "Epoch: 216, Avg_loss: 76.57682291666667\n",
      "Epoch: 217, Avg_loss: 76.26558939615886\n",
      "Epoch: 218, Avg_loss: 75.91556803385417\n",
      "Epoch: 219, Avg_loss: 75.81418863932292\n",
      "Epoch: 220, Avg_loss: 76.1992696126302\n",
      "Epoch: 221, Avg_loss: 75.8115234375\n",
      "Epoch: 222, Avg_loss: 75.83974965413411\n",
      "Epoch: 223, Avg_loss: 75.64146931966145\n",
      "Epoch: 224, Avg_loss: 76.0259272257487\n",
      "Epoch: 225, Avg_loss: 75.82910410563152\n",
      "Epoch: 226, Avg_loss: 75.6851577758789\n",
      "Epoch: 227, Avg_loss: 75.80815887451172\n",
      "Epoch: 228, Avg_loss: 75.74807484944661\n",
      "Epoch: 229, Avg_loss: 75.5473124186198\n",
      "Epoch: 230, Avg_loss: 76.22205861409505\n",
      "Epoch: 231, Avg_loss: 75.76876576741536\n",
      "Epoch: 232, Avg_loss: 75.94060516357422\n",
      "Epoch: 233, Avg_loss: 75.73143768310547\n",
      "Epoch: 234, Avg_loss: 75.34632364908855\n",
      "Epoch: 235, Avg_loss: 75.6983159383138\n",
      "Epoch: 236, Avg_loss: 75.99255879720052\n",
      "Epoch: 237, Avg_loss: 75.41262817382812\n",
      "Epoch: 238, Avg_loss: 75.79080454508464\n",
      "Epoch: 239, Avg_loss: 75.75838724772136\n",
      "Epoch: 240, Avg_loss: 76.07431284586589\n",
      "Epoch: 241, Avg_loss: 75.6080551147461\n",
      "Epoch: 242, Avg_loss: 75.49712880452473\n",
      "Epoch: 243, Avg_loss: 75.52737426757812\n",
      "Epoch: 244, Avg_loss: 75.37267049153645\n",
      "Epoch: 245, Avg_loss: 75.36151377360027\n",
      "Epoch: 246, Avg_loss: 75.66722869873047\n",
      "Epoch: 247, Avg_loss: 75.54434204101562\n",
      "Epoch: 248, Avg_loss: 75.64027913411458\n",
      "Epoch: 249, Avg_loss: 75.58184051513672\n",
      "Epoch: 250, Avg_loss: 75.37222798665364\n",
      "Epoch: 251, Avg_loss: 75.2867431640625\n",
      "Epoch: 252, Avg_loss: 75.3529281616211\n",
      "Epoch: 253, Avg_loss: 75.60821278889973\n",
      "Epoch: 254, Avg_loss: 75.46927642822266\n",
      "Epoch: 255, Avg_loss: 75.21037038167317\n",
      "Epoch: 256, Avg_loss: 75.45377095540364\n",
      "Epoch: 257, Avg_loss: 75.05584971110027\n",
      "Epoch: 258, Avg_loss: 75.32166544596355\n",
      "Epoch: 259, Avg_loss: 75.54580942789714\n",
      "Epoch: 260, Avg_loss: 75.3350346883138\n",
      "Epoch: 261, Avg_loss: 75.4036127726237\n",
      "Epoch: 262, Avg_loss: 75.32273356119792\n",
      "Epoch: 263, Avg_loss: 75.33181762695312\n",
      "Epoch: 264, Avg_loss: 75.57362874348958\n",
      "Epoch: 265, Avg_loss: 75.13574473063152\n",
      "iteration 800, loss 73.389\n",
      "Epoch: 266, Avg_loss: 75.3858159383138\n",
      "Epoch: 267, Avg_loss: 75.20674133300781\n",
      "Epoch: 268, Avg_loss: 75.01565043131511\n",
      "Epoch: 269, Avg_loss: 75.1614278157552\n",
      "Epoch: 270, Avg_loss: 75.22239939371745\n",
      "Epoch: 271, Avg_loss: 75.16932169596355\n",
      "Epoch: 272, Avg_loss: 75.48528289794922\n",
      "Epoch: 273, Avg_loss: 75.16638692220052\n",
      "Epoch: 274, Avg_loss: 75.48774719238281\n",
      "Epoch: 275, Avg_loss: 75.22415924072266\n",
      "Epoch: 276, Avg_loss: 75.04318237304688\n",
      "Epoch: 277, Avg_loss: 75.49357350667317\n",
      "Epoch: 278, Avg_loss: 75.39998626708984\n",
      "Epoch: 279, Avg_loss: 74.90765635172527\n",
      "Epoch: 280, Avg_loss: 75.1192118326823\n",
      "Epoch: 281, Avg_loss: 75.36550649007161\n",
      "Epoch: 282, Avg_loss: 75.20046742757161\n",
      "Epoch: 283, Avg_loss: 75.5277811686198\n",
      "Epoch: 284, Avg_loss: 75.41723378499348\n",
      "Epoch: 285, Avg_loss: 75.37106577555339\n",
      "Epoch: 286, Avg_loss: 75.03713480631511\n",
      "Epoch: 287, Avg_loss: 75.10621388753255\n",
      "Epoch: 288, Avg_loss: 75.07582600911458\n",
      "Epoch: 289, Avg_loss: 75.00376892089844\n",
      "Epoch: 290, Avg_loss: 75.1124038696289\n",
      "Epoch: 291, Avg_loss: 74.99298604329427\n",
      "Epoch: 292, Avg_loss: 75.73576100667317\n",
      "Epoch: 293, Avg_loss: 74.92545572916667\n",
      "Epoch: 294, Avg_loss: 74.93534088134766\n",
      "Epoch: 295, Avg_loss: 74.78736114501953\n",
      "Epoch: 296, Avg_loss: 74.94864654541016\n",
      "Epoch: 297, Avg_loss: 75.08956654866536\n",
      "Epoch: 298, Avg_loss: 75.31941731770833\n",
      "Epoch: 299, Avg_loss: 75.35530344645183\n",
      "Epoch: 300, Avg_loss: 74.88742065429688\n",
      "Epoch: 301, Avg_loss: 74.92184956868489\n",
      "Epoch: 302, Avg_loss: 75.10378774007161\n",
      "Epoch: 303, Avg_loss: 74.76810455322266\n",
      "Epoch: 304, Avg_loss: 74.89465840657552\n",
      "Epoch: 305, Avg_loss: 74.87185923258464\n",
      "Epoch: 306, Avg_loss: 75.23297627766927\n",
      "Epoch: 307, Avg_loss: 74.78556060791016\n",
      "Epoch: 308, Avg_loss: 74.80496215820312\n",
      "Epoch: 309, Avg_loss: 74.80853525797527\n",
      "Epoch: 310, Avg_loss: 74.75904083251953\n",
      "Epoch: 311, Avg_loss: 74.79949188232422\n",
      "Epoch: 312, Avg_loss: 74.77744801839192\n",
      "Epoch: 313, Avg_loss: 75.16681671142578\n",
      "Epoch: 314, Avg_loss: 74.81760915120442\n",
      "Epoch: 315, Avg_loss: 74.69115702311198\n",
      "Epoch: 316, Avg_loss: 75.13454182942708\n",
      "Epoch: 317, Avg_loss: 75.18471272786458\n",
      "Epoch: 318, Avg_loss: 74.82682037353516\n",
      "Epoch: 319, Avg_loss: 74.7801742553711\n",
      "Epoch: 320, Avg_loss: 75.01413472493489\n",
      "Epoch: 321, Avg_loss: 74.62169647216797\n",
      "Epoch: 322, Avg_loss: 74.61402130126953\n",
      "Epoch: 323, Avg_loss: 75.08619944254558\n",
      "Epoch: 324, Avg_loss: 75.41068267822266\n",
      "Epoch: 325, Avg_loss: 74.55008188883464\n",
      "Epoch: 326, Avg_loss: 74.71097056070964\n",
      "Epoch: 327, Avg_loss: 74.5218022664388\n",
      "Epoch: 328, Avg_loss: 75.14876810709636\n",
      "Epoch: 329, Avg_loss: 74.89012908935547\n",
      "Epoch: 330, Avg_loss: 74.85328165690105\n",
      "Epoch: 331, Avg_loss: 74.93408966064453\n",
      "Epoch: 332, Avg_loss: 74.63944753011067\n",
      "iteration 1000, loss 80.239\n",
      "Epoch: 333, Avg_loss: 74.75533803304036\n",
      "Epoch: 334, Avg_loss: 74.34246063232422\n",
      "Epoch: 335, Avg_loss: 75.24171702067058\n",
      "Epoch: 336, Avg_loss: 74.70954895019531\n",
      "Epoch: 337, Avg_loss: 74.78611246744792\n",
      "Epoch: 338, Avg_loss: 74.69298553466797\n",
      "Epoch: 339, Avg_loss: 74.8197021484375\n",
      "Epoch: 340, Avg_loss: 74.47556813557942\n",
      "Epoch: 341, Avg_loss: 74.63250223795573\n",
      "Epoch: 342, Avg_loss: 74.68894704182942\n",
      "Epoch: 343, Avg_loss: 74.53384399414062\n",
      "Epoch: 344, Avg_loss: 74.62514750162761\n",
      "Epoch: 345, Avg_loss: 74.70003763834636\n",
      "Epoch: 346, Avg_loss: 74.54651896158855\n",
      "Epoch: 347, Avg_loss: 74.83832550048828\n",
      "Epoch: 348, Avg_loss: 74.71049245198567\n",
      "Epoch: 349, Avg_loss: 74.34421284993489\n",
      "Epoch: 350, Avg_loss: 74.9472427368164\n",
      "Epoch: 351, Avg_loss: 74.83192189534505\n",
      "Epoch: 352, Avg_loss: 74.80409749348958\n",
      "Epoch: 353, Avg_loss: 74.67799123128255\n",
      "Epoch: 354, Avg_loss: 74.6485087076823\n",
      "Epoch: 355, Avg_loss: 74.47774759928386\n",
      "Epoch: 356, Avg_loss: 74.30892181396484\n",
      "Epoch: 357, Avg_loss: 74.38459014892578\n",
      "Epoch: 358, Avg_loss: 74.28906504313152\n",
      "Epoch: 359, Avg_loss: 74.49919891357422\n",
      "Epoch: 360, Avg_loss: 74.36948649088542\n",
      "Epoch: 361, Avg_loss: 74.21675109863281\n",
      "Epoch: 362, Avg_loss: 74.38289388020833\n",
      "Epoch: 363, Avg_loss: 74.25371551513672\n",
      "Epoch: 364, Avg_loss: 74.40898895263672\n",
      "Epoch: 365, Avg_loss: 74.38311258951823\n",
      "Epoch: 366, Avg_loss: 74.6422602335612\n",
      "Epoch: 367, Avg_loss: 74.33399709065755\n",
      "Epoch: 368, Avg_loss: 74.24972025553386\n",
      "Epoch: 369, Avg_loss: 74.48894500732422\n",
      "Epoch: 370, Avg_loss: 74.39945220947266\n",
      "Epoch: 371, Avg_loss: 74.24221801757812\n",
      "Epoch: 372, Avg_loss: 74.1624043782552\n",
      "Epoch: 373, Avg_loss: 74.61392211914062\n",
      "Epoch: 374, Avg_loss: 74.70233662923177\n",
      "Epoch: 375, Avg_loss: 74.73889414469402\n",
      "Epoch: 376, Avg_loss: 74.13180541992188\n",
      "Epoch: 377, Avg_loss: 74.5601069132487\n",
      "Epoch: 378, Avg_loss: 74.21465555826823\n",
      "Epoch: 379, Avg_loss: 74.93111165364583\n",
      "Epoch: 380, Avg_loss: 74.16121164957683\n",
      "Epoch: 381, Avg_loss: 74.13199361165364\n",
      "Epoch: 382, Avg_loss: 74.11141459147136\n",
      "Epoch: 383, Avg_loss: 74.15917205810547\n",
      "Epoch: 384, Avg_loss: 74.3395284016927\n",
      "Epoch: 385, Avg_loss: 74.05220286051433\n",
      "Epoch: 386, Avg_loss: 74.28093719482422\n",
      "Epoch: 387, Avg_loss: 74.70521545410156\n",
      "Epoch: 388, Avg_loss: 74.0168228149414\n",
      "Epoch: 389, Avg_loss: 74.20585632324219\n",
      "Epoch: 390, Avg_loss: 73.91651153564453\n",
      "Epoch: 391, Avg_loss: 74.46563212076823\n",
      "Epoch: 392, Avg_loss: 74.19932047526042\n",
      "Epoch: 393, Avg_loss: 73.77675120035808\n",
      "Epoch: 394, Avg_loss: 73.90756225585938\n",
      "Epoch: 395, Avg_loss: 74.23657735188802\n",
      "Epoch: 396, Avg_loss: 73.88092041015625\n",
      "Epoch: 397, Avg_loss: 73.96820576985677\n",
      "Epoch: 398, Avg_loss: 74.27684783935547\n",
      "iteration 1200, loss 69.233\n",
      "Epoch: 399, Avg_loss: 73.94611104329427\n",
      "Epoch: 400, Avg_loss: 73.77909088134766\n",
      "Epoch: 401, Avg_loss: 74.10326131184895\n",
      "Epoch: 402, Avg_loss: 74.43119303385417\n",
      "Epoch: 403, Avg_loss: 73.96348826090495\n",
      "Epoch: 404, Avg_loss: 74.71811421712239\n",
      "Epoch: 405, Avg_loss: 74.09842427571614\n",
      "Epoch: 406, Avg_loss: 74.24813334147136\n",
      "Epoch: 407, Avg_loss: 74.21424611409505\n",
      "Epoch: 408, Avg_loss: 73.82695770263672\n",
      "Epoch: 409, Avg_loss: 74.0414530436198\n",
      "Epoch: 410, Avg_loss: 73.84154764811198\n",
      "Epoch: 411, Avg_loss: 73.85712178548177\n",
      "Epoch: 412, Avg_loss: 73.92336018880208\n",
      "Epoch: 413, Avg_loss: 74.26191965738933\n",
      "Epoch: 414, Avg_loss: 74.40685780843098\n",
      "Epoch: 415, Avg_loss: 73.99885813395183\n",
      "Epoch: 416, Avg_loss: 73.8489761352539\n",
      "Epoch: 417, Avg_loss: 73.76662953694661\n",
      "Epoch: 418, Avg_loss: 73.91404978434245\n",
      "Epoch: 419, Avg_loss: 73.83066304524739\n",
      "Epoch: 420, Avg_loss: 73.85029856363933\n",
      "Epoch: 421, Avg_loss: 74.40468851725261\n",
      "Epoch: 422, Avg_loss: 73.98782602945964\n",
      "Epoch: 423, Avg_loss: 73.61892954508464\n",
      "Epoch: 424, Avg_loss: 73.80779266357422\n",
      "Epoch: 425, Avg_loss: 74.19486490885417\n",
      "Epoch: 426, Avg_loss: 73.60735321044922\n",
      "Epoch: 427, Avg_loss: 73.93542226155598\n",
      "Epoch: 428, Avg_loss: 73.54330698649089\n",
      "Epoch: 429, Avg_loss: 73.62492370605469\n",
      "Epoch: 430, Avg_loss: 73.64239247639973\n",
      "Epoch: 431, Avg_loss: 73.56010437011719\n",
      "Epoch: 432, Avg_loss: 74.00139617919922\n",
      "Epoch: 433, Avg_loss: 73.83748118082683\n",
      "Epoch: 434, Avg_loss: 73.48852284749348\n",
      "Epoch: 435, Avg_loss: 73.66882832845052\n",
      "Epoch: 436, Avg_loss: 73.37630208333333\n",
      "Epoch: 437, Avg_loss: 73.43769836425781\n",
      "Epoch: 438, Avg_loss: 74.02276865641277\n",
      "Epoch: 439, Avg_loss: 73.52778625488281\n",
      "Epoch: 440, Avg_loss: 73.45648701985677\n",
      "Epoch: 441, Avg_loss: 73.64756266276042\n",
      "Epoch: 442, Avg_loss: 73.36897786458333\n",
      "Epoch: 443, Avg_loss: 74.24753824869792\n",
      "Epoch: 444, Avg_loss: 74.0930404663086\n",
      "Epoch: 445, Avg_loss: 73.41968536376953\n",
      "Epoch: 446, Avg_loss: 73.40082295735677\n",
      "Epoch: 447, Avg_loss: 74.48176829020183\n",
      "Epoch: 448, Avg_loss: 73.45370992024739\n",
      "Epoch: 449, Avg_loss: 73.79963684082031\n",
      "Epoch: 450, Avg_loss: 73.46452077229817\n",
      "Epoch: 451, Avg_loss: 73.14207458496094\n",
      "Epoch: 452, Avg_loss: 73.39410146077473\n",
      "Epoch: 453, Avg_loss: 73.44950358072917\n",
      "Epoch: 454, Avg_loss: 73.43545277913411\n",
      "Epoch: 455, Avg_loss: 73.22322845458984\n",
      "Epoch: 456, Avg_loss: 73.88009389241536\n",
      "Epoch: 457, Avg_loss: 73.6139424641927\n",
      "Epoch: 458, Avg_loss: 73.06482950846355\n",
      "Epoch: 459, Avg_loss: 73.45077768961589\n",
      "Epoch: 460, Avg_loss: 73.55615997314453\n",
      "Epoch: 461, Avg_loss: 73.17109934488933\n",
      "Epoch: 462, Avg_loss: 73.49338277180989\n",
      "Epoch: 463, Avg_loss: 73.3397216796875\n",
      "Epoch: 464, Avg_loss: 73.57973225911458\n",
      "Epoch: 465, Avg_loss: 72.96339416503906\n",
      "iteration 1400, loss 68.200\n",
      "Epoch: 466, Avg_loss: 73.17777506510417\n",
      "Epoch: 467, Avg_loss: 74.02588907877605\n",
      "Epoch: 468, Avg_loss: 73.50547536214192\n",
      "Epoch: 469, Avg_loss: 73.76451365152995\n",
      "Epoch: 470, Avg_loss: 73.77508544921875\n",
      "Epoch: 471, Avg_loss: 73.01208750406902\n",
      "Epoch: 472, Avg_loss: 73.2054672241211\n",
      "Epoch: 473, Avg_loss: 73.09729258219402\n",
      "Epoch: 474, Avg_loss: 72.92431386311848\n",
      "Epoch: 475, Avg_loss: 73.06380716959636\n",
      "Epoch: 476, Avg_loss: 73.03891499837239\n",
      "Epoch: 477, Avg_loss: 73.6567866007487\n",
      "Epoch: 478, Avg_loss: 72.96470387776692\n",
      "Epoch: 479, Avg_loss: 73.36227925618489\n",
      "Epoch: 480, Avg_loss: 72.91951243082683\n",
      "Epoch: 481, Avg_loss: 73.09445699055989\n",
      "Epoch: 482, Avg_loss: 72.95840708414714\n",
      "Epoch: 483, Avg_loss: 73.98615010579427\n",
      "Epoch: 484, Avg_loss: 72.90370178222656\n",
      "Epoch: 485, Avg_loss: 72.82207743326823\n",
      "Epoch: 486, Avg_loss: 72.94786071777344\n",
      "Epoch: 487, Avg_loss: 73.10733795166016\n",
      "Epoch: 488, Avg_loss: 72.7917989095052\n",
      "Epoch: 489, Avg_loss: 73.37666320800781\n",
      "Epoch: 490, Avg_loss: 73.67085520426433\n",
      "Epoch: 491, Avg_loss: 72.77440897623698\n",
      "Epoch: 492, Avg_loss: 72.79759979248047\n",
      "Epoch: 493, Avg_loss: 73.71736907958984\n",
      "Epoch: 494, Avg_loss: 73.65203603108723\n",
      "Epoch: 495, Avg_loss: 73.48052469889323\n",
      "Epoch: 496, Avg_loss: 72.71922302246094\n",
      "Epoch: 497, Avg_loss: 72.84134928385417\n",
      "Epoch: 498, Avg_loss: 73.26580301920573\n",
      "Epoch: 499, Avg_loss: 72.54224395751953\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from training import NeuralProcessTrainer\n",
    "\n",
    "batch_size = 1\n",
    "num_context = 17\n",
    "num_target = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "np_trainer = NeuralProcessTrainer(device, neuralprocess, optimizer,\n",
    "                                  num_context_range=(num_context, num_context),\n",
    "                                  num_extra_target_range=(num_target, num_target), \n",
    "                                  print_freq=200)\n",
    "\n",
    "neuralprocess.training = True\n",
    "np_trainer.train(data_loader, 500)\n",
    "plt.plot(range(len(np_trainer.epoch_loss_history)),np_trainer.epoch_loss_history)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### predict without context\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# for batch in data_loader:\n",
    "#     break\n",
    "# x_target, y_target = batch\n",
    "# print(y_target)\n",
    "# # print(x_target)\n",
    "# # print(x_target.size())\n",
    "# for i in range(10):\n",
    "#     z_sample = torch.randn((1, z_dim))\n",
    "#     mu, _ = neuralprocess.xz_to_y(x_target, z_sample)\n",
    "#     print(mu.detach())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### predict with context\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "prediceted value: \n",
      "tensor([[[25.3523],\n",
      "         [23.7180],\n",
      "         [25.4146],\n",
      "         [25.6979],\n",
      "         [23.9916],\n",
      "         [25.3205],\n",
      "         [25.3970],\n",
      "         [23.4944],\n",
      "         [26.1596],\n",
      "         [25.0127],\n",
      "         [25.8448],\n",
      "         [26.1884],\n",
      "         [25.3187],\n",
      "         [24.9655],\n",
      "         [24.2725],\n",
      "         [24.3344],\n",
      "         [25.1401],\n",
      "         [25.1700]]])\n",
      "target value:\n",
      "tensor([[[63.],\n",
      "         [62.],\n",
      "         [48.],\n",
      "         [28.],\n",
      "         [53.],\n",
      "         [30.],\n",
      "         [26.],\n",
      "         [53.],\n",
      "         [30.],\n",
      "         [19.],\n",
      "         [21.],\n",
      "         [30.],\n",
      "         [30.],\n",
      "         [37.],\n",
      "         [51.],\n",
      "         [53.],\n",
      "         [28.],\n",
      "         [40.]]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from utils import context_target_split\n",
    "\n",
    "for batch in data_loader:\n",
    "    break\n",
    "\n",
    "# Use batch to create random set of context points\n",
    "x, y = batch\n",
    "# print(x.size())\n",
    "x_context, y_context, _, _ = context_target_split(x[0:1], y[0:1], \n",
    "                                                  num_context, \n",
    "                                                  num_target)\n",
    "# print(x_context.size())\n",
    "neuralprocess.training = False\n",
    "from datasets import FaceFeatureTestData\n",
    "\n",
    "testDataset = FaceFeatureTestData()\n",
    "testData_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
    "for x_target, y_target in testData_loader:\n",
    "    # print('target size:')\n",
    "    # print(x_target.size())\n",
    "    # print(y_target.size())\n",
    "    p_y_pred = neuralprocess(x_context, y_context, x_target)\n",
    "    # # Extract mean of distribution\n",
    "    mu = p_y_pred.loc.detach()\n",
    "    print('prediceted value: ')\n",
    "    print(mu)\n",
    "    print('target value:')\n",
    "    print(y_target)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}