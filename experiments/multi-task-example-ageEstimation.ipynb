{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Process for age estimation(multi-task)\n",
    "\n",
    "This notebook shows how to train and sample from a Neural Process for a class of age estimation in multi-task learning way\n",
    "There are (num_of_persons) tasks.\n",
    "In each task, there are (num_of_images) context points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets.datasets import FaceFeatureData\n",
    "\n",
    "# Create dataset\n",
    "\n",
    "# 3 tasks\n",
    "num_of_people = 3\n",
    "# 18 examples\n",
    "num_of_images=18\n",
    "dataset = FaceFeatureData(num_of_people=num_of_people,num_of_images=num_of_images)\n",
    "\n",
    "#82 different people(batch_num)\n",
    "#18 different images each people(batch_size)\n",
    "#x_dim = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Neural Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from model.NeuralProcessModel import NeuralProcess\n",
    "\n",
    "x_dim = 2048\n",
    "y_dim = 1\n",
    "r_dim = 50  # Dimension of representation of context points\n",
    "z_dim = 50  # Dimension of sampled latent variable\n",
    "h_dim = 50  # Dimension of hidden layers in encoder and decoder\n",
    "\n",
    "neuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Neural Process 1st time\n",
    "the first time(all the parameter will be updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from trainer.NP_trainer import NeuralProcessTrainer\n",
    "from data_loader.data_loader import FGNetDataLoader\n",
    "\n",
    "batch_size = 1\n",
    "# num of training set = 17\n",
    "num_context = 17\n",
    "# num of test set = 1\n",
    "num_target = 1\n",
    "\n",
    "data_loader = FGNetDataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "np_trainer = NeuralProcessTrainer(device, neuralprocess, optimizer,\n",
    "                                  num_context_range=(num_context, num_context),\n",
    "                                  num_extra_target_range=(num_target, num_target), \n",
    "                                  data_loader=data_loader)\n",
    "\n",
    "neuralprocess.training = True\n",
    "np_trainer.train(100)\n",
    "#save first model parameters trained on the whole dataset\n",
    "torch.save(neuralprocess.state_dict(), r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\age_estimation\\firstWholeTrained.ckpt')\n",
    "plt.plot(range(len(np_trainer.epoch_loss_history)),np_trainer.epoch_loss_history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Neural Process 2nd time\n",
    "(the parameter of encoder will be frozen)\n",
    "\n",
    "the structure of neural process network(3-layer network):\n",
    "layer 1: xy_to_r\n",
    "\n",
    "layer 2: r_to_mu_sigma\n",
    "\n",
    "layer 3: xz_to_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "singlePersonDatasets = []\n",
    "for idx in range(num_of_people):\n",
    "    singlePersonDataset = FaceFeatureData(num_of_people=num_of_people,num_of_images=num_of_images,index=idx)\n",
    "    singlePersonDatasets.append(singlePersonDataset)\n",
    "\n",
    "for idx, singlePersonDataset in enumerate(singlePersonDatasets):\n",
    "    #load model\n",
    "\n",
    "    smallNeuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)\n",
    "    smallNeuralprocess.load_state_dict(torch.load(r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\age_estimation\\firstWholeTrained.ckpt'))\n",
    "    #Freeze the encoder part of each model\n",
    "    for child in smallNeuralprocess.children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        break\n",
    "    singleData_loader = FGNetDataLoader(singlePersonDataset, batch_size=batch_size, shuffle=True)\n",
    "    smallOptimizer = torch.optim.Adam(smallNeuralprocess.parameters(), lr=3e-5)\n",
    "    smallNp_trainer = NeuralProcessTrainer(device, smallNeuralprocess, smallOptimizer,\n",
    "                                  num_context_range=(num_context, num_context),\n",
    "                                  num_extra_target_range=(num_target, num_target), \n",
    "                                  data_loader=data_loader)\n",
    "    smallNeuralprocess.training = True\n",
    "    smallNp_trainer.train(100)\n",
    "    #save first model parameters trained on the whole dataset\n",
    "    path = r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\age_estimation\\smallTrained\\smallTrained' + str(idx) + r'.ckpt'\n",
    "    torch.save(smallNeuralprocess.state_dict(),path)\n",
    "    plt.plot(range(len(smallNp_trainer.epoch_loss_history)),smallNp_trainer.epoch_loss_history)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct input to MergeNet\n",
    "Let new dataset(new person who is not in trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trainer.NP_trainer import NeuralProcessTrainer\n",
    "from datasets.datasets import FaceFeatureTestData\n",
    "import os\n",
    "\n",
    "\n",
    "for batch in data_loader:\n",
    "    break\n",
    "# Use batch to create random set of context points\n",
    "x, y = batch\n",
    "x_context, y_context, _, _ =  NeuralProcessTrainer.context_target_split(x[0:1], y[0:1], \n",
    "                                                  num_context, \n",
    "                                                  num_target)\n",
    "\n",
    "modelPath = r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\age_estimation\\smallTrained'\n",
    "models = os.listdir(modelPath)\n",
    "smallModels = map(lambda x: os.path.join(modelPath, x), models)\n",
    "\n",
    "num_of_test_images = 18\n",
    "test_target = 0\n",
    "resultsOnPretrainedModelsList = [] \n",
    "for idx, root_dir in enumerate(smallModels):\n",
    "    #load model\n",
    "    testNeuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)\n",
    "    testModelPath = r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\age_estimation\\smallTrained\\smallTrained' + str(idx) + r'.ckpt'\n",
    "    testNeuralprocess.load_state_dict(torch.load(testModelPath))\n",
    "    testNeuralprocess.training = False\n",
    "\n",
    "    testDataset = FaceFeatureTestData()\n",
    "    testData_loader = FGNetDataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
    "    resultsOnPretrainedModel = []\n",
    "    for x_target, y_target in testData_loader:\n",
    "        test_target = y_target\n",
    "        avg_mu = 0\n",
    "        for i in range(10):\n",
    "            p_y_pred = testNeuralprocess(x_context, y_context, x_target)\n",
    "            # Extract mean of distribution\n",
    "            mu = p_y_pred.loc.detach()\n",
    "            avg_mu += mu\n",
    "        avg_mu = avg_mu / 10\n",
    "        avg_mu = avg_mu.view(18)\n",
    "        resultsOnPretrainedModel.append(avg_mu.tolist())\n",
    "    resultsOnPretrainedModelsList.append(resultsOnPretrainedModel)\n",
    "\n",
    "resultsOnPretrainedModels = []\n",
    "for i in range(num_of_test_images):\n",
    "    resultsWithSinglePerson = []\n",
    "    for list in resultsOnPretrainedModelsList:\n",
    "        resultsWithSinglePerson.append(list[0][i])\n",
    "    resultsOnPretrainedModels.append(resultsWithSinglePerson)\n",
    "resultsOnPretrainedModels = torch.FloatTensor(resultsOnPretrainedModels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MergeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from model.models import MergeNet\n",
    "\n",
    "mergeNet = MergeNet(number_of_trained_people=num_of_people)\n",
    "mergeOptimizer = torch.optim.Adam(mergeNet.parameters(), lr=3e-3)\n",
    "mergeEpoch = 350\n",
    "criterion = torch.nn.MSELoss()\n",
    "test_target = test_target.view(num_of_test_images,1)\n",
    "merge_loss_history = []\n",
    "for epoch in range(mergeEpoch):\n",
    "    mergeOptimizer.zero_grad()\n",
    "    mergeResult = mergeNet(resultsOnPretrainedModels)\n",
    "    loss = criterion(mergeResult, test_target)\n",
    "    loss.backward()\n",
    "    mergeOptimizer.step()\n",
    "    print(\"Epoch: {}, loss: {}\".format(epoch, loss))\n",
    "    merge_loss_history.append(loss)\n",
    "plt.plot(range(len(merge_loss_history)),merge_loss_history)\n",
    "plt.show()\n",
    "#save mergeNet\n",
    "path = r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\mergeNet.ckpt'\n",
    "torch.save(mergeNet.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import datasets\n",
    "\n",
    "finalTestDataset = FaceFeatureTestData(r'D:\\PycharmProjects\\ANP\\neural-processes\\datasets\\FinalTestFeatureVector')\n",
    "finalTestData_loader = FGNetDataLoader(finalTestDataset, batch_size=batch_size, shuffle=True)\n",
    "finalResultsOnPretrainedModels = datasets.ConstructInputToMergeNet(num_of_test_images,finalTestData_loader)\n",
    "testMergeNet = MergeNet(number_of_trained_people=num_of_people)\n",
    "testMergeNet.load_state_dict(torch.load(r'D:\\PycharmProjects\\ANP\\neural-processes\\trained_models\\mergeNet.ckpt'))\n",
    "\n",
    "final_predict_value = testMergeNet(finalResultsOnPretrainedModels)\n",
    "print('final result: ')\n",
    "print(final_predict_value)\n",
    "for _,target_y in finalTestData_loader:\n",
    "    print(target_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}